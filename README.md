# АНАЛИЗ ДАННЫХ И ИСКУССТВЕННЫЙ ИНТЕЛЛЕКТ [in GameDev]
Отчет по лабораторной работе #4 выполнил(а):
- Мосин Дмитрий Сергеевич
- РИ210936
Отметка о выполнении заданий (заполняется студентом):

| Задание | Выполнение | Баллы |
| ------ | ------ | ------ |
| Задание 1 | * | 60 |
| Задание 2 | * | 20 |
| Задание 3 | # | 20 |

знак "*" - задание выполнено; знак "#" - задание не выполнено;

Работу проверили:
- к.т.н., доцент Денисов Д.В.
- к.э.н., доцент Панов М.А.
- ст. преп., Фадеев В.О.

[![N|Solid](https://cldup.com/dTxpPi9lDf.thumb.png)](https://nodesource.com/products/nsolid)

[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)

Структура отчета

- Данные о работе: название работы, фио, группа, выполненные задания.
- Цель работы.
- Задание 1.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 2.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Задание 3.
- Код реализации выполнения задания. Визуализация результатов выполнения (если применимо).
- Выводы.
- ✨Magic ✨

## Цель работы
Познакомиться с работой перцептрона на практике при помощи движка Unity. Реализовать перцептрон который умеет решать логические операции.



## Задание 1
### В проекте реализовать перцептрон, который умеет производить вычисления: OR, AND, NAND, XOR, и дать комментарии о кореектности работы.
----------------------------------------------------------------------------------------------------------------------------------------

### Ход работы:

(1) Первым неделом необходимо создать новый проект в Unity. Так как взаимодействовать мы будем только с консолью, неважно 2D или 3D проект мы создадим. Я выбрал 3D проект. В нем мы создаем пустой объект, на котором будет прекреплен скрипт работы парсептрона

![image](https://user-images.githubusercontent.com/100014698/205030038-c5b96de0-321f-4fd1-b1f9-bed9df1dd708.png)

----------------------------------------------------------------------------------------------------------------------------------------

(2) В папку проекта добавляем скрипт (Perceptron.cs) который уже написан преподавателями и предоставлен нам для выполнения лабораторной работы

``` C#
using System.Collections;
using System.Collections.Generic;
using UnityEngine;

[System.Serializable]
public class TrainingSet
{
	public double[] input;
	public double output;
}

public class Perceptron : MonoBehaviour
{

	public TrainingSet[] ts;
	double[] weights = { 0, 0 };
	double bias = 0;
	double totalError = 0;

	double DotProductBias(double[] v1, double[] v2)
	{
		if (v1 == null || v2 == null)
			return -1;

		if (v1.Length != v2.Length)
			return -1;

		double d = 0;
		for (int x = 0; x < v1.Length; x++)
		{
			d += v1[x] * v2[x];
		}

		d += bias;

		return d;
	}

	double CalcOutput(int i)
	{
		double dp = DotProductBias(weights, ts[i].input);
		if (dp > 0) return (1);
		return (0);
	}

	void InitialiseWeights()
	{
		for (int i = 0; i < weights.Length; i++)
		{
			weights[i] = Random.Range(-1.0f, 1.0f);
		}
		bias = Random.Range(-1.0f, 1.0f);
	}

	void UpdateWeights(int j)
	{
		double error = ts[j].output - CalcOutput(j);
		totalError += Mathf.Abs((float)error);
		for (int i = 0; i < weights.Length; i++)
		{
			weights[i] = weights[i] + error * ts[j].input[i];
		}
		bias += error;
	}

	double CalcOutput(double i1, double i2)
	{
		double[] inp = new double[] { i1, i2 };
		double dp = DotProductBias(weights, inp);
		if (dp > 0) return (1);
		return (0);
	}

	void Train(int epochs)
	{
		InitialiseWeights();

		for (int e = 0; e < epochs; e++)
		{
			totalError = 0;
			for (int t = 0; t < ts.Length; t++)
			{
				UpdateWeights(t);
				Debug.Log("W1: " + (weights[0]) + " W2: " + (weights[1]) + " B: " + bias);
			}
			Debug.Log("TOTAL ERROR: " + totalError);
		}
	}

	void Start()
	{
		Train(8);
		Debug.Log("Test 0 0: " + CalcOutput(0, 0));
		Debug.Log("Test 0 1: " + CalcOutput(0, 1));
		Debug.Log("Test 1 0: " + CalcOutput(1, 0));
		Debug.Log("Test 1 1: " + CalcOutput(1, 1));
	}

	void Update()
	{

	}
}
```

----------------------------------------------------------------------------------------------------------------------------------------

(3) В данном скрипте нам достаточно взаимодействовать с методом **Train(int epochs)** - он влияет на количество эпох обучения пeрсептрона, переменная **ts** с помощью которой мы будем задавать значения входа и выхода и переменная **totalError**, которая будет считать количество несоотвествующих выводов.

----------------------------------------------------------------------------------------------------------------------------------------

(4) Этот сприпт мы препляем на наш пустой объект.

![image](https://user-images.githubusercontent.com/100014698/205038789-26fe5d5f-d7fd-47f9-9e85-1ab967311afb.png)

----------------------------------------------------------------------------------------------------------------------------------------

(5) В качестве входных и выходных значений мы зададим таблицу первой нужной нам логической операции OR. Вспомним таблицу для жтой операции:

| A | B | A OR B |
| --- | --- | --- |
| 0 | 0 |    0   |
| 0 | 1 |    1   |
| 1 | 0 |    1   |
| 1 | 1 |    1   |

----------------------------------------------------------------------------------------------------------------------------------------

(6) Зададим значения из этой таблицы для переменной **ts**:

![image](https://user-images.githubusercontent.com/100014698/205038916-d4ab8e8f-c70e-41c6-a47a-65b33bcf65fa.png)

----------------------------------------------------------------------------------------------------------------------------------------


(7) Установим **1 эпоху** для обучения и увидим что нашлись два несоотвествующих вывода: 

![image](https://user-images.githubusercontent.com/100014698/205039379-752a56ff-2c4f-41a8-b03b-64611b07e64a.png)

----------------------------------------------------------------------------------------------------------------------------------------

(8) Установим **4 эпохи** для обучения и увидим что так же нашлись два несоотвествующих вывода: 

![image](https://user-images.githubusercontent.com/100014698/205039569-343a2cf1-e41a-41eb-b5d8-44d9daa9308c.png)

----------------------------------------------------------------------------------------------------------------------------------------

(9) Запустим еще раз **4 эпохи** и видим что на этот раз нашелся только 1 несоответствующий выход: 

![image](https://user-images.githubusercontent.com/100014698/205040110-a2bdb8c2-b9d6-4672-bfb6-c98b688e4371.png)

----------------------------------------------------------------------------------------------------------------------------------------

(10) Установим **5 эпох** для обучения и увидим что на этот раз он подобрал правильные веса уже на **3эпохе**:

![image](https://user-images.githubusercontent.com/100014698/205040329-8479428e-517d-466e-8db6-e99092b70321.png)

----------------------------------------------------------------------------------------------------------------------------------------

(11) Запустим еще раз:

![image](https://user-images.githubusercontent.com/100014698/205040570-73c60030-2ee2-4eeb-ad80-8f67a97a64e6.png)

----------------------------------------------------------------------------------------------------------------------------------------

## Вывод по OR: 
После запусков нескольких раз, можно убедиться что перцептрон уверенно находит правильные веса в пределах **5 эпох**

(12) Проведем те же исследования со второй логической операцией AND:

| A | B | A AND B |
| --- | --- | --- |
| 0 | 0 |    0   |
| 0 | 1 |    0   |
| 1 | 0 |    0   |
| 1 | 1 |    1   |

----------------------------------------------------------------------------------------------------------------------------------------

(13) Установим входные и выходные значения для переменной **ts** и запустим сразу **3 эпохи**, так как очевидно, что первые **2 эпохи** вряд ли будут успешными, и как мы можем увидеть даже **3 эпох** не достаточно:

![image](https://user-images.githubusercontent.com/100014698/205043191-00c93983-e027-4112-b9e2-d14bdd617dd3.png)

----------------------------------------------------------------------------------------------------------------------------------------

(14) Установим **4 эпохи** и увидим весьма и весьма интересный результат, что в **3 эпохе**  результат был лучше, нежели в **4 эпохе**

![image](https://user-images.githubusercontent.com/100014698/205043966-73924b14-5f66-48e7-acf6-310f34fa17d3.png)

----------------------------------------------------------------------------------------------------------------------------------------

(15) Установим **5 эпох** и увидим что парцептрон подобрал правильные веса:

![image](https://user-images.githubusercontent.com/100014698/205044201-c05f396c-51ee-4a30-ad49-4ca8fb61a8ea.png)

----------------------------------------------------------------------------------------------------------------------------------------


## Вывод по AND: 
После нескольких запусков, можно убедиться что перцептрон все так же уверенно находит правильные веса в пределах **5 эпох**

----------------------------------------------------------------------------------------------------------------------------------------

(16) Проведем те же исследования со второй логической операцией NAND:

| A | B | A NAND B |
| --- | --- | --- |
| 0 | 0 |    1   |
| 0 | 1 |    1   |
| 1 | 0 |    1   |
| 1 | 1 |    0   |

----------------------------------------------------------------------------------------------------------------------------------------

(17) Сразу же начнем с **4 эпох**, как и у предыдущих логических операций, **4 эпох** не хватает для подбора весов: 

![image](https://user-images.githubusercontent.com/100014698/205052512-1b84e909-cdb5-4b96-800c-bdb6fd0b994b.png)

----------------------------------------------------------------------------------------------------------------------------------------

(18) После утановке **5 эпох** перцептрон так же не способен надежно после каждой попытки подбирать веса: 

![image](https://user-images.githubusercontent.com/100014698/205053405-4c70566d-52e2-434c-ba59-b889f1e101ae.png)

----------------------------------------------------------------------------------------------------------------------------------------

(19) Установим **8 эпох** и запустим несколько раз, посмотрим скольких эпох достаточно, чаще всего результатом было **6-7 эпох**: 

![image](https://user-images.githubusercontent.com/100014698/205053661-4e10cf69-5a7d-4cc7-9d93-343a9bb24974.png)

----------------------------------------------------------------------------------------------------------------------------------------

## Вывод по NAND: 
После нескольких запусков, можно убедиться что перцептрон все так же уверенно находит правильные веса в пределах **7 эпох**

----------------------------------------------------------------------------------------------------------------------------------------


(20) Следующая рассматриваемая логическая операция - **XOR**:

| A | B | A XOR B |
| --- | --- | --- |
| 0 | 0 |    0   |
| 0 | 1 |    1   |
| 1 | 0 |    1   |
| 1 | 1 |    0   |


(21) Из лекции мы знаем, что однслоный перцептрон не должен быть способным находить веса для данной логической операции, проверим это и запустим **10 эпох**. Даже после **10 эпох** количество неправильных выходных данных было равно 4/4:

![image](https://user-images.githubusercontent.com/100014698/205054488-43bbb983-0b03-40fc-b69f-cffcb09c404f.png)

----------------------------------------------------------------------------------------------------------------------------------------

## Вывод по XOR: 
Как мы знаем из лекции однослойный перцептрон способен решать только линейные операции, а **XOR** таковой не является. 
Тем неменее исходя из формулы: 

						A XOR B = (A OR B) AND (A NAND B)  
						
Мы можем сделать вывод, что если мы добавим еще два слоя перцептрона (**OR** и **NAND**) натренируем сначала их, а затем начнем тренировать конечный **AND** этих операций с выходом (0, 1, 1, 0) то мы в теории можем получить ответ, но для этого нужно вносить изменения в код: 

(22) Для начала вместо одной переменной типа TrainingSet определим 3, каждая из которых будет отвечать за конкретную операцию:

``` C#
public class Perceptron : MonoBehaviour
{

	public TrainingSet[] ts_OR;		// <--- операция A OR B
	public TrainingSet[] ts_NAND;		// <--- операция A NAND B
	public TrainingSet[] ts_XOR;		// <--- операция (A OR B) AND (A NAND B)
	double[] weights = { 0, 0 };
	double bias = 0;
	double totalError = 0;
}
```


(23) Затем переназначим методы внутри класса, которые раньше взаимодействовали с переменной **ts**, теперь они будут дополнительно полуать на вход ту операцию, которую обучают в данный момент


``` C#
public class Perceptron : MonoBehaviour
{

	public TrainingSet[] ts_OR;
	public TrainingSet[] ts_NAND;
	public TrainingSet[] ts_XOR;
	double[] weights = { 0, 0 };
	double bias = 0;
	double totalError = 0;

	double DotProductBias(double[] v1, double[] v2)
	{
		if (v1 == null || v2 == null)
			return -1;

		if (v1.Length != v2.Length)
			return -1;

		double d = 0;
		for (int x = 0; x < v1.Length; x++)
		{
			d += v1[x] * v2[x];
		}

		d += bias;

		return d;
	}

	double CalcOutput(int i, TrainingSet[] ts)		// <--- Here
	{
		double dp = DotProductBias(weights, ts[i].input);
		if (dp > 0) return (1);
		return (0);
	}

	void InitialiseWeights()
	{
		for (int i = 0; i < weights.Length; i++)
		{
			weights[i] = Random.Range(-1.0f, 1.0f);
		}
		bias = Random.Range(-1.0f, 1.0f);
	}

	void UpdateWeights(int j, TrainingSet[] ts)		// <--- Here
	{
		double error = ts[j].output - CalcOutput(j, ts);
		totalError += Mathf.Abs((float)error);
		for (int i = 0; i < weights.Length; i++)
		{
			weights[i] = weights[i] + error * ts[j].input[i];
		}
		bias += error;
	}

	double CalcOutput(double i1, double i2)
	{
		double[] inp = new double[] { i1, i2 };
		double dp = DotProductBias(weights, inp);
		if (dp > 0) return (1);
		return (0);
	}

	void Train(int epochs, TrainingSet[] ts)		// <--- And here
	{
		InitialiseWeights();

		for (int e = 0; e < epochs; e++)
		{
			totalError = 0;
			for (int t = 0; t < ts.Length; t++)
			{
				UpdateWeights(t, ts);
				Debug.Log("W1: " + (weights[0]) + " W2: " + (weights[1]) + " B: " + bias);
			}
			Debug.Log("TOTAL ERROR: " + totalError);
		}
	}
}
```

(24) Наконец добавим в метод **Start()** два новых массива, которые будут хранить выходные значения для ts_OR и ts_NAND. А так же добавим их обучения: 

``` C#
void Start()
{
	double[] ts_OR_values = new double [ts_OR.Length];
	double[] ts_NAND_values = new double [ts_NAND.Length];


	Train(6, ts_OR);
	for (int i = 0; i < ts_OR.Length; i++)
	{
		ts_OR_values[i] = CalcOutput(ts_OR[i].input[0], ts_OR[i].input[1]);
	}

	Train(6, ts_NAND);
	for (int i = 0; i < ts_OR.Length; i++)
	{
		ts_NAND_values[i] = CalcOutput(ts_NAND[i].input[0], ts_NAND[i].input[1]);
	}


	Train(6, ts_XOR);
        Debug.Log("Test 0 0: " + CalcOutput(ts_OR_values[0], ts_NAND_values[0]));
        Debug.Log("Test 0 1: " + CalcOutput(ts_OR_values[1], ts_NAND_values[1]));
        Debug.Log("Test 1 0: " + CalcOutput(ts_OR_values[2], ts_NAND_values[2]));
        Debug.Log("Test 1 1: " + CalcOutput(ts_OR_values[3], ts_NAND_values[3]));
}
```


(25) Запустим получившуюся программу несколько раз и получим на выходе верные значения, что не может не радовать
![image](https://user-images.githubusercontent.com/100014698/205064483-ec9ee1ce-c26e-4965-a80c-87de8567d8df.png)

## Вывод по XOR (2): 
Однослойной перцептрон не способен решать нелинейные задачи, и поэтому для нахождения весов для функции **XOR** нам нужно добавлять дополнительные слои, что мы и сделали.


## Задание 2
### Построить графики зависимости количества эпох от ошибки обучения. Указать от чего зависит необходимое количество эпох обучения.



## Выводы

В ходе лабораторной работы, я познакомился с программными средствами для создания программы с машинным обучением. Познакомился с библиотеками -  mlagents и torch.
Научился взаимодействовать объектами, проводить итерации для машинного обучения и выводить результаты на объекты.
Познакомился с новыми компонентами объектов - Decision Requester, Behavior Parameters.

| Plugin | README |
| ------ | ------ |
| Dropbox | [plugins/dropbox/README.md][PlDb] |
| GitHub | [plugins/github/README.md][PlGh] |
| Google Drive | [plugins/googledrive/README.md][PlGd] |
| OneDrive | [plugins/onedrive/README.md][PlOd] |
| Medium | [plugins/medium/README.md][PlMe] |
| Google Analytics | [plugins/googleanalytics/README.md][PlGa] |

## Powered by

**BigDigital Team: Denisov | Fadeev | Panov**
